/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pytorch_lightning/loggers/wandb.py:396: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.
  "There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse"
Global seed set to 23
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
  | Name                 | Type               | Params
------------------------------------------------------------
0 | resnet               | ResNet             | 14.4 M
1 | fc1                  | Linear             | 15.4 K
2 | fc2                  | Linear             | 7.7 K
3 | fc3                  | Linear             | 33
4 | train_macro_accuracy | MulticlassAccuracy | 0
5 | val_macro_accuracy   | MulticlassAccuracy | 0
6 | test_macro_accuracy  | MulticlassAccuracy | 0
7 | train_accuracy       | MulticlassAccuracy | 0
8 | val_accuracy         | MulticlassAccuracy | 0
9 | test_accuracy        | MulticlassAccuracy | 0
------------------------------------------------------------
14.4 M    Trainable params
0         Non-trainable params
14.4 M    Total params
57.764    Total estimated model params size (MB)
/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:229: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  category=PossibleUserWarning,
Train dataset length: 10
Validation dataset length: 4
Sanity Checking DataLoader 0:   0%|                                                                                   | 0/2 [00:00<?, ?it/s]
/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:84: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 2. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.

Sanity Checking DataLoader 0:  50%|█████████████████████████████████████▌                                     | 1/2 [00:01<00:01,  1.48s/it]
/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  category=PossibleUserWarning,
/Users/MaryFetter/Documents/GitHub/NCANDA_Contrastive/multimodal/model.py:114: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).


Epoch 0:  14%|██████████▍                                                              | 1/7 [00:06<00:39,  6.58s/it, loss=1.65, v_num=fyqh]
/Users/MaryFetter/Documents/GitHub/NCANDA_Contrastive/multimodal/model.py:114: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).

Epoch 0:  29%|█████████████████████▏                                                    | 2/7 [00:13<00:32,  6.59s/it, loss=1.3, v_num=fyqh]
/Users/MaryFetter/Documents/GitHub/NCANDA_Contrastive/multimodal/model.py:114: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).

Epoch 0:  43%|███████████████████████████████▋                                          | 3/7 [00:21<00:28,  7.01s/it, loss=1.4, v_num=fyqh]
/Users/MaryFetter/Documents/GitHub/NCANDA_Contrastive/multimodal/model.py:114: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).

Epoch 0:  57%|█████████████████████████████████████████▋                               | 4/7 [00:28<00:21,  7.08s/it, loss=1.28, v_num=fyqh]
/Users/MaryFetter/Documents/GitHub/NCANDA_Contrastive/multimodal/model.py:114: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
Epoch 0:  71%|████████████████████████████████████████████████████▊                     | 5/7 [00:37<00:14,  7.42s/it, loss=1.2, v_num=fyqh]


Validation DataLoader 0:  50%|████████████████████████████████████████                                        | 1/2 [00:02<00:02,  2.89s/it]

`Trainer.fit` stopped: `max_epochs=1` reached.